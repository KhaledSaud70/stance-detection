{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TRB-XhuO-dVs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai\n",
        "# !pip install --upgrade langchain\n",
        "!pip install --upgrade python-dotenv\n",
        "!pip install datasets -q\n",
        "!pip install scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NoraAlt/Mawqif-Arabic-Stance.git\n",
        "!git clone https://github.com/aub-mind/arabert/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WG2cEWjGP2A",
        "outputId": "7c175604-279b-4a2f-f9c1-5a371665457d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mawqif-Arabic-Stance' already exists and is not an empty directory.\n",
            "fatal: destination path 'arabert' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data = load_dataset(\"NoraAlt/Mawqif_Stance-Detection\", split='train')\n",
        "df = train_data.to_pandas()\n",
        "\n",
        "mapping = {None: 0, 'Favor': 1, 'Against': 2}\n",
        "df['stance'] = df['stance'].apply(lambda x: mapping[x])\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.15, stratify=df['stance'], random_state=42)\n",
        "\n",
        "reverse_mapping = {0: \"None\", 1: 'Favor', 2: 'Against'}\n",
        "train_df['stance'] = train_df['stance'].apply(lambda x: reverse_mapping[x])\n",
        "val_df['stance'] = val_df['stance'].apply(lambda x: reverse_mapping[x])"
      ],
      "metadata": {
        "id": "ilZSwuL6a4On"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape, val_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs6EFtCAa9o_",
        "outputId": "914d9c5f-d783-4728-cb89-d13b3b876f7d"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2976, 14), (526, 14))"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the validation set for future use in evaluation.\n",
        "val_df.to_csv(\"val_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "s2G-0-FZ3u3o"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from arabert.preprocess import ArabertPreprocessor\n",
        "arabert_prep = ArabertPreprocessor(model_name=\"bert-base-arabertv02\")"
      ],
      "metadata": {
        "id": "1rMxVB-nbSPo"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'] = train_df['text'].apply(lambda text: arabert_prep.preprocess(text))\n",
        "# val_df['text'] = val_df['text'].apply(lambda text: arabert_prep.preprocess(text))"
      ],
      "metadata": {
        "id": "W60pxVyQc6-F"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.text.values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI2fRF70e64c",
        "outputId": "51daed9a-d128-4630-e432-b533c5dd2f36"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "محافظ سوهاج . . خلو قوائم ” العزل المنزلي ” من مرضى كورونا . . و تطعيم 2 مليون مواطن ضد الفيروس URL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_gpt_dataset(df, system_prompt, file_path=None, mode='train'):\n",
        "    messages = []\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        for idx, row in df.iterrows():\n",
        "            if mode == 'train':\n",
        "                messages.append(\n",
        "                    {\"messages\": [{\"role\": \"system\", \"content\": system_prompt},\n",
        "                                  {\"role\": \"user\", \"content\": row[\"text\"]},\n",
        "                                  {\"role\": \"assistant\", \"content\": row[\"stance\"]}]}\n",
        "                )\n",
        "            elif mode == 'test':\n",
        "                messages.append(\n",
        "                    {\"messages\": [{\"role\": \"system\", \"content\": system_prompt},\n",
        "                                  {\"role\": \"user\", \"content\": row[\"text\"]}]}\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"Invalid mode. Mode must be either 'train' or 'test'.\")\n",
        "\n",
        "            json.dump(messages[-1], f)\n",
        "            f.write('\\n')\n",
        "\n",
        "    return messages\n"
      ],
      "metadata": {
        "id": "gJ2sNGJDTMUY"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"\n",
        "\n",
        "train_messages = create_gpt_dataset(train_df, system_prompt, file_path='train_instances.jsonl')\n",
        "# val_messages = create_gpt_dataset(val_df, system_prompt, file_path='val_instances.jsonl', mode='test')"
      ],
      "metadata": {
        "id": "WfMvxWN0g_yh"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, sample in enumerate(train_messages[:5]):\n",
        "    print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SuJxeKyYO7n",
        "outputId": "d148b5db-c313-4150-affa-4cf29306d889"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [{'role': 'system', 'content': \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"}, {'role': 'user', 'content': 'محافظ سوهاج . . خلو قوائم ” العزل المنزلي ” من مرضى كورونا . . و تطعيم 2 مليون مواطن ضد الفيروس URL'}, {'role': 'assistant', 'content': 'None'}]}\n",
            "{'messages': [{'role': 'system', 'content': \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"}, {'role': 'user', 'content': 'قوة التكنولوجيا و استعمال الذكاء الاصطناعي اللي موجودة لسه محدود الانتشار . . التحول الالكتروني حاليا متعطل علي قدرة و شجاعة الناس في التغيير . . التغيير في انك تتخلص من القديم وتستعمل الجديد . . { تتخلص من القديم بكل انواعة للاسف . . } # digitaltransformation # obstacles'}, {'role': 'assistant', 'content': 'Favor'}]}\n",
            "{'messages': [{'role': 'system', 'content': \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"}, {'role': 'user', 'content': 'فئة كبييرة جتهم كورونا مثل السلام عليكم وراحت ولا حسو فيها ونسبة الشفاء من كورونا من غير تطعيم 99 . 9 ف لا تعظمون اللقاح أكثر المرض مو خطير على أغلب الناس .'}, {'role': 'assistant', 'content': 'Against'}]}\n",
            "{'messages': [{'role': 'system', 'content': \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"}, {'role': 'user', 'content': 'جاءت # رؤية _ 2030 في انسجام تام مع خصائص المجتمع السعودي وثقافته الأصيلة ؛ لنجد تمكين المرأة من ممارسة دورها القيادي في تنمية المجتمع ، يتصاعد في مختلف الميادين . # قطوف # جمعة # المرأة _ في _ 2030'}, {'role': 'assistant', 'content': 'Favor'}]}\n",
            "{'messages': [{'role': 'system', 'content': \"You are an assistant that, given an Arabic tweet, detect the writers' stance (Favor, Against, or None). None means there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position.\"}, {'role': 'user', 'content': 'الحين الكل من القطاعاات الحكوميه اصبح يفعل التحول الالكتروني بخدماته و توجه الاسكان لها التحول بيخدم المستفيد'}, {'role': 'assistant', 'content': 'Favor'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "client =  OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "aaRZEYkG7hM0"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_response = client.files.create(file=open('train_instances.jsonl', 'rb'), purpose='fine-tune')"
      ],
      "metadata": {
        "id": "DHH8ZvCV7lnH"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_response"
      ],
      "metadata": {
        "id": "SIn98yHl7-Ap"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the file ID from the file_response.\n",
        "file_id = 'your_train_file_id'"
      ],
      "metadata": {
        "id": "j3QLYq5w8Fpp"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ],
      "metadata": {
        "id": "EK14Y2di8JO-"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response"
      ],
      "metadata": {
        "id": "HR8IJgabEewh"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the job ID from the response.\n",
        "job_id = 'your_job_id'"
      ],
      "metadata": {
        "id": "4JLeHGN3EjOZ"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# client.fine_tuning.jobs.retrieve(job_id)"
      ],
      "metadata": {
        "id": "8Sbq9YzfElN-"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the model ID by running client.fine_tuning.jobs.retrieve(job_id) and get the id from key (fine_tuned_model).\n",
        "model_id = 'your_ft_model_id'"
      ],
      "metadata": {
        "id": "3nTftbX4blp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_openai_params(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    max_tokens=2,\n",
        "    top_p=1,\n",
        "):\n",
        "    \"\"\"Set OpenAI parameters.\"\"\"\n",
        "    openai_params = {\n",
        "        'model': model,\n",
        "        'temperature': temperature,\n",
        "        'max_tokens': max_tokens,\n",
        "        'top_p': top_p\n",
        "    }\n",
        "    return openai_params\n",
        "\n",
        "def predict(params, messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model = params['model'],\n",
        "        messages = messages,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "tL39qR0ChiX-"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blind_test_df = pd.read_csv('Mawqif-Arabic-Stance/Data/Mawqif_AllTargets_Blind Test.csv')\n",
        "blind_test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q93Apm7oKreg",
        "outputId": "249bcd72-061b-42fb-eea3-d3e2dfc2a175"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(619, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_openai_params(model=model_id)\n",
        "\n",
        "def format_test(row):\n",
        "    formatted_message =  [{\"role\": \"system\", \"content\": system_prompt},\n",
        "                          {\"role\": \"user\", \"content\": row[\"text\"]}]\n",
        "    return formatted_message\n",
        "\n",
        "def generate_predictions(params, test_df, output_csv_path):\n",
        "    test_df_copy = test_df.copy()\n",
        "\n",
        "    test_df_copy['text'] = test_df_copy['text'].apply(lambda text: arabert_prep.preprocess(text))\n",
        "    test_df_copy['prediction'] = None\n",
        "\n",
        "    for idx, row in test_df_copy.iterrows():\n",
        "        test_message = format_test(row)\n",
        "        pred = predict(params, messages=test_message)\n",
        "        test_df_copy.at[idx, 'prediction'] = pred\n",
        "\n",
        "    test_df_copy['prediction'] = test_df_copy['prediction'].fillna('NONE')\n",
        "    test_df_copy['prediction'] = test_df_copy['prediction'].str.upper()\n",
        "\n",
        "    test_df_copy = test_df_copy[['ID', 'target', 'text', 'prediction']]\n",
        "    test_df_copy.columns = ['ID', 'Target', 'Tweet', 'Stance']\n",
        "    test_df_copy.to_csv(output_csv_path, index=None, header=True, sep='\\t')\n",
        "\n",
        "generate_predictions(params, val_df, output_csv_path='gpt3.5_predictions.csv')"
      ],
      "metadata": {
        "id": "GPwLFkvzJ9Le"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_format_csv(input_csv_path, output_csv_path):\n",
        "    df = pd.read_csv(input_csv_path)\n",
        "    df['stance'] = df['stance'].fillna('None')\n",
        "    df['stance'] = df['stance'].str.upper()\n",
        "\n",
        "    df = df[['ID', 'target', 'text', 'stance']]\n",
        "    df.columns = ['ID', 'Target', 'Tweet', 'Stance']\n",
        "\n",
        "    df.to_csv(output_csv_path, index=None, header=True, sep='\\t')\n",
        "\n",
        "\n",
        "load_and_format_csv('val_data.csv', 'validation.csv')"
      ],
      "metadata": {
        "id": "np9G4ZhJ8gwo"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result on a 15% validation set.\n",
        "\n",
        "!python stanceEval.py /content/validation.csv /content/gpt3.5_predictions.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_94Gxmw88aJR",
        "outputId": "3e62be72-39bc-42c3-874c-53f96f3e92ce"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "============\n",
            "Results for Target: Women empowerment\n",
            "============\n",
            "FAVOR     precision: 0.8889 recall: 0.9677 f-score: 0.9266\n",
            "AGAINST   precision: 0.8913 recall: 0.8723 f-score: 0.8817\n",
            "------------\n",
            "Macro F: 0.9042\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============\n",
            "Results for Target: Covid Vaccine\n",
            "============\n",
            "FAVOR     precision: 0.8889 recall: 0.9474 f-score: 0.9172\n",
            "AGAINST   precision: 0.8617 recall: 0.9101 f-score: 0.8852\n",
            "------------\n",
            "Macro F: 0.9012\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============\n",
            "Results for Target: Digital Transformation\n",
            "============\n",
            "FAVOR     precision: 0.8855 recall: 0.9431 f-score: 0.9134\n",
            "AGAINST   precision: 0.5000 recall: 0.4118 f-score: 0.4516\n",
            "------------\n",
            "Macro F: 0.6825\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============\n",
            "Overall Macro F1-score across all targets: 0.8293\n",
            "============\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating predictions for the blind test data using a model trained on 85% of the training data.\n",
        "\n",
        "generate_predictions(params, blind_test_df, output_csv_path='gpt3.5_blindTest_pred.csv')"
      ],
      "metadata": {
        "id": "29pNRiJ-fHNB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}